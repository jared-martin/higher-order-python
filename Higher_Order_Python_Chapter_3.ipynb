{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Higher Order Python - Chapter 3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNZOWjV8NesL1VLx8tDa6IL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jared-martin/higher-order-python/blob/main/Higher_Order_Python_Chapter_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Cachine and Memoization\n",
        "\n",
        "We saw in Section 1.8 that a natural recursive function can sometimes perform extremely badly. An easy and general solution to many of these performance problems, as well as some that arise in nonrecursive contexts, is caching."
      ],
      "metadata": {
        "id": "2RNbVYzhc5UX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Caching Fixes Recursion"
      ],
      "metadata": {
        "id": "Thtj-pZneWpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fib(month: int) -> int:\n",
        "    if month < 2:\n",
        "        return 1\n",
        "    else:\n",
        "        return fib(month - 1) + fib(month - 2)\n",
        "\n",
        "# Takes a few seconds\n",
        "fib(35)"
      ],
      "metadata": {
        "id": "A7beN1sLegvj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e44349d0-e8db-4fcc-c8de-f687bdcbfe3c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14930352"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we saw in Section 1.8, this function runs slowly for most arguments, because it wastes time recomputing results it has already computed. For example, `fib(20)` needs to compute `fib(19)` and `fib(18)`, but `fib(19)` also computes `fib(18)`, as well as `fib(17)`, which is also computed once by each of the calls to `fib(18)`. This is a common problem with recursive functions, and it is fixed by caching."
      ],
      "metadata": {
        "id": "YZqrKjbPeqH3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Inline Cachine\n",
        "\n",
        "The most straightforward way to add caching to a function is to give the function a ~~private hash~~ dictionary."
      ],
      "metadata": {
        "id": "lD4b4y7Ofmcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In the book, cache is declared outside fib but in a \"block\" next to fib,\n",
        "# making the variable static but *not* global.\n",
        "cache = dict()\n",
        "\n",
        "def fib(month: int) -> int:\n",
        "    try:\n",
        "        return cache[month]\n",
        "    except KeyError:\n",
        "        if month < 2:\n",
        "            cache[month] = 1\n",
        "        else:\n",
        "            cache[month] = fib(month - 1) + fib(month - 2)\n",
        "        return cache[month]\n",
        "\n",
        "# Instantaneous!\n",
        "fib(35)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdmMsRZZgMuZ",
        "outputId": "4f32879e-e863-4f4d-9c12-4d0b0e01046b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14930352"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Good Ideas\n",
        "\n",
        "Caching comes up over and over in real programs. Almost any program will contain functions where caching might yield a performance win. But the best property of caching is that it’s *mechanical*. If you have a function, and you would like to speed it up, you might rewrite the function, or introduce a better data structure, or a more sophisticated algorithm. This might require ingenuity, which is always in short supply. But adding caching is a no-brainer; the caching transformation is always pretty much the same."
      ],
      "metadata": {
        "id": "QEMaieFjlxma"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4 Memoization\n",
        "\n",
        "Adding the caching code to functions is not very much trouble. And as we saw, the changes required are the same for almost any function. Why not, then, get the computer to do it for us?"
      ],
      "metadata": {
        "id": "9d5jQgUUqcIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In the book, the author imports a module from the Perl standard library, so\n",
        "# we'll do the Python equivalent here.\n",
        "from functools import lru_cache\n",
        "\n",
        "\n",
        "@lru_cache(maxsize=None)\n",
        "def fib(month: int) -> int:\n",
        "    if month < 2:\n",
        "        return 1\n",
        "    else:\n",
        "        return fib(month - 1) + fib(month - 2)\n",
        "\n",
        "fib(35)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PL7JOndJqXUQ",
        "outputId": "a8d1a413-a1de-4cb9-ffc6-248693b4af37"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14930352"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.5 The Memoize Module\n",
        "\n",
        "Memoize gets a function name (or reference) as its argument. It manufactures a new function that maintains a cache and looks up its arguments in the cache. If the new function finds the arguments in the cache, it returns the cached value; if not, it calls the original function, saves the return value in the cache, and returns it to the original caller.\n",
        "\n",
        "Having manufactured this new function, Memoize then installs it into the Perl symbol table in place of the original function so that when you think you’re calling the original function, you actually get the new cache manager function instead."
      ],
      "metadata": {
        "id": "q51EcELNtW5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections.abc import Callable\n",
        "\n",
        "\n",
        "def memoize(func: Callable) -> Callable:\n",
        "    cache = dict()\n",
        "    def stub(*args, **kwargs):\n",
        "        # This function isn't recursive because it doesn't actually call itself\n",
        "        key = str(args) + str(kwargs)\n",
        "        try:\n",
        "            return cache[key]\n",
        "        except KeyError:\n",
        "            cache[key] = func(*args, **kwargs)\n",
        "            return cache[key]\n",
        "    return stub\n",
        "\n",
        "\n",
        "# Note that the syntax in the book - fastfib = memoize(fib) - while valid, won't\n",
        "# work here, since in Python fastfib is memoized but fib isn't, and fib still\n",
        "# calls its non-memoized self recursively.\n",
        "@memoize\n",
        "def fastfib(month: int) -> int:\n",
        "    if month < 2:\n",
        "        return 1\n",
        "    else:\n",
        "        return fastfib(month - 1) + fastfib(month - 2)\n",
        "\n",
        "fastfib(35)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKYYIwi6tl45",
        "outputId": "3660cc2d-8cf4-4a69-8748-ac43d70c2f96"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14930352"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.5.2 Lexical Closure\n",
        "\n",
        "Now another point might be worrying you. Since the value of `func` persists as long as the stub does, what happens if we call memoize a second time, while the first stub is still extant? Will the assignment to `func` in the second call clobber the value that the first stub was using?\n",
        "The answer is no; everything works perfectly. This is because ~~Perl’s anony- mous functions~~ Python's functions have a property called lexical closure. When an ~~anonymous~~ *(in Python, this holds true for named functions as well)* function is created, Perl packages up its pad, including all the bindings that are in scope, and attaches them to the CV. A function packaged up with an environment in this way is called a closure."
      ],
      "metadata": {
        "id": "ajH0vZJq-_3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_counter(n) -> Callable:\n",
        "    # In Python, closures don't need to be anonymous, and anonymous functions\n",
        "    # can't contain assignments, so we use a named function called inner.\n",
        "    def inner():\n",
        "        nonlocal n  # In Python, this is needed if we're reassigning n\n",
        "        print(f'n is {n}')\n",
        "        n += 1\n",
        "    return inner\n",
        "\n",
        "x = make_counter(7)\n",
        "y = make_counter(20)\n",
        "\n",
        "x(); x(); x()\n",
        "y(); y(); y()\n",
        "x()  # n is the same as it was the first 3 times we invoked x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZ5mb9vJ8Dh0",
        "outputId": "f3f0b1e0-8cc3-48f1-be75-094d83168717"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n is 7\n",
            "n is 8\n",
            "n is 9\n",
            "n is 20\n",
            "n is 21\n",
            "n is 22\n",
            "n is 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Python, it feels more natural to use an object to keep track of state than a closure, like this:"
      ],
      "metadata": {
        "id": "Es7P2plI_7u8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Counter:\n",
        "\n",
        "    def __init__(self, n):\n",
        "        self.n = n\n",
        "\n",
        "    def __call__(self):\n",
        "        print(f'n is {self.n}')\n",
        "        self.n += 1\n",
        "\n",
        "x = Counter(7)\n",
        "y = Counter(20)\n",
        "x(); x(); x()\n",
        "y(); y(); y()\n",
        "x()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLcKg6fRAL1I",
        "outputId": "e69eb8bf-8aa7-4faf-ac15-c9a5a5686f8b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n is 7\n",
            "n is 8\n",
            "n is 9\n",
            "n is 20\n",
            "n is 21\n",
            "n is 22\n",
            "n is 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.6.2 Functions with Side Effects\n",
        "\n",
        "Many functions are called not for their return values but for their side effects.  Suppose you have written a program that formats a computer uptime report and delivers the report to the printer to be printed.  Probably the return value is not interesting, and caching it is silly.  Even if the return value is interesting, memoization is still inappropriate.  The function might complete much more quickly after the first run, because of the memoization, but your boss would not be impressed, because it would have returned the old cached return value immediately, without bothering to actually print the report."
      ],
      "metadata": {
        "id": "SybjaL6BBGRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.6.3 Functions That Return References\n",
        "\n",
        "Functions that return references to values that may be modified by their callers must not be memoized.  To see the potential problem, consider this example:"
      ],
      "metadata": {
        "id": "374G1sQoA6hp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@lru_cache(maxsize=None)\n",
        "def iota(n):\n",
        "    return list(range(1, n + 1))\n",
        "\n",
        "i10 = iota(10)\n",
        "j10 = iota(10)\n",
        "i10.pop()\n",
        "print(j10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjxu3fE1A6Al",
        "outputId": "4770a144-3fcc-4c33-d9b2-a3a3729bbfcc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first call to `iota(10)` generates a new, fresh anonymous ~~array~~ list of the numbers from 1 to 10, and returns a reference to this ~~array~~ list. This reference is automatically placed in the cache, and is also stored into `i10`. The second call to `iota(10)` fetches the same reference from the cache and stores it into `j10`. Both `i10` and `j10` now refer to the same array--we say that they are *aliases* for the array.\n",
        "\n",
        "When we change the value of the array via the `i10` alias, the change affects the value that is stored in `j10`!  This was probably not what the caller was expecting, and it would not have happened if we had not memoized `iota`. Memoization is supposed to be an optimization. This means it is supposed to speed up the program without changing its behavior."
      ],
      "metadata": {
        "id": "IEb6Yf91ChDb"
      }
    }
  ]
}